# WebContentExtractor - é€šç”¨ç½‘é¡µå†…å®¹æå–å·¥å…·

ä¸€ä¸ªå¼ºå¤§çš„ã€å¯é…ç½®çš„ç½‘é¡µå†…å®¹æå–å·¥å…·ï¼Œç”¨äºæ‰¹é‡æå–ç½‘é¡µæ–‡ç« å¹¶ä¿å­˜ä¸ºMarkdownæ ¼å¼ï¼Œæ”¯æŒè‡ªåŠ¨ä¸‹è½½å›¾ç‰‡ã€‚

## âœ¨ ç‰¹æ€§

- ğŸš€ **æ‰¹é‡æå–** - æ”¯æŒæ‰¹é‡æå–å¤šç¯‡æ–‡ç« 
- ğŸ“ **æ ¼å¼ä¿ç•™** - å®Œæ•´ä¿ç•™ç²—ä½“ã€æ–œä½“ã€ä»£ç ã€é“¾æ¥ç­‰æ ¼å¼
- ğŸ–¼ï¸ **å›¾ç‰‡ä¸‹è½½** - è‡ªåŠ¨ä¸‹è½½æ–‡ç« å›¾ç‰‡å¹¶æ›´æ–°å¼•ç”¨
- âš™ï¸ **é«˜åº¦å¯é…ç½®** - çµæ´»çš„é…ç½®ç³»ç»Ÿï¼Œé€‚åº”ä¸åŒç½‘ç«™
- ğŸ“¦ **é¢„è®¾æ¨¡æ¿** - å†…ç½®å¸¸ç”¨ç½‘ç«™çš„é…ç½®æ¨¡æ¿
- ğŸ” **CSSé€‰æ‹©å™¨** - æ”¯æŒCSSé€‰æ‹©å™¨å’Œæ ‡ç­¾åé€‰æ‹©
- ğŸ“Š **ç´¢å¼•ç”Ÿæˆ** - è‡ªåŠ¨ç”Ÿæˆæ–‡ç« ç´¢å¼•
- ğŸ›¡ï¸ **é”™è¯¯å¤„ç†** - å®Œå–„çš„é”™è¯¯å¤„ç†å’Œå¤±è´¥è®°å½•

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
pip install requests beautifulsoup4
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

> ğŸ’¡ **æ–°ç”¨æˆ·æ¨è**: æŸ¥çœ‹ [å•ç¯‡æ–‡ç« æå–æŒ‡å—.md](./å•ç¯‡æ–‡ç« æå–æŒ‡å—.md) è·å–æ›´ç®€å•çš„å…¥é—¨æ•™ç¨‹  
> ğŸ§¹ **ä»»åŠ¡å®Œæˆå**: æŸ¥çœ‹ [æ¸…ç†è¯´æ˜.md](./æ¸…ç†è¯´æ˜.md) äº†è§£å¦‚ä½•æ¸…ç†ä¸´æ—¶æ–‡ä»¶

### æå–å•ç¯‡æ–‡ç« ï¼ˆæœ€ç®€å•ï¼‰

```python
from WebContentExtractor import WebContentExtractor, ConfigTemplates

# 1. é€‰æ‹©é¢„è®¾é…ç½®
config = ConfigTemplates.aliyun_developer()  # é˜¿é‡Œäº‘å¼€å‘è€…ç¤¾åŒº
config.output_dir = "æˆ‘çš„æ–‡ç« "

# 2. æå–æ–‡ç« 
extractor = WebContentExtractor(config)
results = extractor.extract_articles([
    {
        "title": "Kubernetesæ¶æ„è¯¦è§£",
        "url": "https://developer.aliyun.com/article/1635071"
    }
])

print(f"æˆåŠŸ: {results['success_count']} ç¯‡")
```

**è¾“å‡ºç»“æ„**:
```
æˆ‘çš„æ–‡ç« /
â””â”€â”€ Kubernetesæ¶æ„è¯¦è§£/
    â”œâ”€â”€ Kubernetesæ¶æ„è¯¦è§£.md
    â””â”€â”€ imgs/
        â”œâ”€â”€ image_1.png
        â””â”€â”€ ...
```

### æ‰¹é‡æå–å¤šç¯‡æ–‡ç« 

```python
from WebContentExtractor import WebContentExtractor, ConfigTemplates

# 1. ä½¿ç”¨é¢„è®¾é…ç½®
config = ConfigTemplates.golangstar()
config.output_dir = "æˆ‘çš„æ–‡ç« "

# 2. å‡†å¤‡æ–‡ç« åˆ—è¡¨
articles = [
    {
        "title": "æ–‡ç« æ ‡é¢˜1",
        "url": "https://example.com/article1.html"
    },
    {
        "title": "æ–‡ç« æ ‡é¢˜2", 
        "url": "https://example.com/article2.html"
    }
]

# 3. åˆ›å»ºæå–å™¨å¹¶æ‰§è¡Œ
extractor = WebContentExtractor(config)
results = extractor.extract_articles(articles)

print(f"æˆåŠŸ: {results['success_count']} ç¯‡")
print(f"å¤±è´¥: {results['fail_count']} ç¯‡")
```

### è‡ªå®šä¹‰é…ç½®

```python
from WebContentExtractor import WebContentExtractor, ExtractionConfig

# åˆ›å»ºè‡ªå®šä¹‰é…ç½®
config = ExtractionConfig(
    base_url="https://myblog.com",           # ç½‘ç«™åŸºç¡€URL
    output_dir="extracted_articles",          # è¾“å‡ºç›®å½•
    main_content_selector="article.post",     # ä¸»å†…å®¹é€‰æ‹©å™¨
    title_selector="h1.title",                # æ ‡é¢˜é€‰æ‹©å™¨
    skip_selectors=['nav', '.sidebar'],       # è¦è·³è¿‡çš„å…ƒç´ 
    download_images=True,                     # ä¸‹è½½å›¾ç‰‡
    image_skip_keywords=['icon', 'logo'],     # è·³è¿‡çš„å›¾ç‰‡å…³é”®è¯
    timeout=30,                               # è¯·æ±‚è¶…æ—¶
    delay=1.0,                                # è¯·æ±‚é—´éš”(ç§’)
)

extractor = WebContentExtractor(config)
```

## ğŸ“š è¯¦ç»†é…ç½®è¯´æ˜

### ExtractionConfig å‚æ•°

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `base_url` | str | "" | ç½‘ç«™åŸºç¡€URLï¼Œç”¨äºå¤„ç†ç›¸å¯¹è·¯å¾„ |
| `output_dir` | str | "extracted_articles" | è¾“å‡ºç›®å½•è·¯å¾„ |
| `main_content_selector` | str | "main" | ä¸»å†…å®¹åŒºåŸŸçš„CSSé€‰æ‹©å™¨æˆ–æ ‡ç­¾å |
| `title_selector` | str | "h1" | æ ‡é¢˜é€‰æ‹©å™¨ |
| `skip_selectors` | List[str] | ['nav', 'aside', 'footer'] | è¦è·³è¿‡çš„å…ƒç´ é€‰æ‹©å™¨åˆ—è¡¨ |
| `download_images` | bool | True | æ˜¯å¦ä¸‹è½½å›¾ç‰‡ |
| `image_skip_keywords` | List[str] | ['icon', 'avatar', 'logo'] | è·³è¿‡åŒ…å«è¿™äº›å…³é”®è¯çš„å›¾ç‰‡ |
| `images_folder_name` | str | "images" | å›¾ç‰‡æ–‡ä»¶å¤¹åç§° |
| `preserve_bold` | bool | True | ä¿ç•™ç²—ä½“æ ¼å¼ |
| `preserve_italic` | bool | True | ä¿ç•™æ–œä½“æ ¼å¼ |
| `preserve_code` | bool | True | ä¿ç•™ä»£ç æ ¼å¼ |
| `preserve_links` | bool | True | ä¿ç•™é“¾æ¥ |
| `timeout` | int | 30 | HTTPè¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) |
| `delay` | float | 1.0 | è¯·æ±‚é—´éš”æ—¶é—´(ç§’) |
| `headers` | Dict | é»˜è®¤User-Agent | HTTPè¯·æ±‚å¤´ |
| `file_encoding` | str | 'utf-8' | æ–‡ä»¶ç¼–ç  |
| `create_index` | bool | True | æ˜¯å¦åˆ›å»ºç´¢å¼•æ–‡ä»¶ |
| `verbose` | bool | True | æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯ |
| `save_failed_urls` | bool | True | æ˜¯å¦ä¿å­˜å¤±è´¥çš„URLåˆ—è¡¨ |

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: æå–æŠ€æœ¯åšå®¢æ–‡ç« 

```python
config = ExtractionConfig(
    base_url="https://techblog.com",
    main_content_selector="article.post-content",
    title_selector="h1.post-title",
    download_images=True,
)
```

### åœºæ™¯2: åªæå–çº¯æ–‡æœ¬ï¼ˆä¸ä¸‹è½½å›¾ç‰‡ï¼‰

```python
config = ExtractionConfig(
    download_images=False,  # å…³é—­å›¾ç‰‡ä¸‹è½½
    main_content_selector=".content",
)
```

### åœºæ™¯3: ä»JSONæ–‡ä»¶æ‰¹é‡æå–

```python
import json

# articles.json æ ¼å¼:
# [
#   {"title": "æ–‡ç« 1", "url": "https://..."},
#   {"title": "æ–‡ç« 2", "url": "https://..."}
# ]

with open('articles.json', 'r', encoding='utf-8') as f:
    articles = json.load(f)

config = ExtractionConfig(base_url="https://example.com")
extractor = WebContentExtractor(config)
results = extractor.extract_articles(articles)
```

### åœºæ™¯4: æ…¢é€Ÿçˆ¬å–ï¼ˆé¿å…è¢«å°ï¼‰

```python
config = ExtractionConfig(
    delay=3.0,  # æ¯æ¬¡è¯·æ±‚é—´éš”3ç§’
    timeout=60,  # è¶…æ—¶æ—¶é—´60ç§’
    headers={
        'User-Agent': 'Mozilla/5.0 ...',
        'Referer': 'https://example.com',
    }
)
```

## ğŸ“ è¾“å‡ºç»“æ„

æå–åçš„æ–‡ä»¶ç»“æ„ï¼š

```
output_dir/
â”œâ”€â”€ README.md                    # è‡ªåŠ¨ç”Ÿæˆçš„ç´¢å¼•æ–‡ä»¶
â”œâ”€â”€ failed_urls.json            # å¤±è´¥çš„URLåˆ—è¡¨ï¼ˆå¦‚æœ‰ï¼‰
â”œâ”€â”€ æ–‡ç« 1/
â”‚   â”œâ”€â”€ æ–‡ç« 1.md
â”‚   â””â”€â”€ imgs/                   # å›¾ç‰‡æ–‡ä»¶å¤¹ï¼ˆé»˜è®¤åç§°ä¸ºimgsï¼‰
â”‚       â”œâ”€â”€ image_1.png
â”‚       â”œâ”€â”€ image_2.png
â”‚       â””â”€â”€ ...
â”œâ”€â”€ æ–‡ç« 2/
â”‚   â”œâ”€â”€ æ–‡ç« 2.md
â”‚   â””â”€â”€ imgs/
â”‚       â””â”€â”€ ...
â””â”€â”€ ...
```

> ğŸ’¡ **æç¤º**: å›¾ç‰‡æ–‡ä»¶å¤¹åç§°å¯é€šè¿‡ `config.images_folder_name` è‡ªå®šä¹‰

## ğŸ”§ é¢„è®¾é…ç½®æ¨¡æ¿

### ä½¿ç”¨é¢„è®¾æ¨¡æ¿

```python
from WebContentExtractor import ConfigTemplates

# é˜¿é‡Œäº‘å¼€å‘è€…ç¤¾åŒºé…ç½®
config = ConfigTemplates.aliyun_developer()

# golangstar.cn é…ç½®
config = ConfigTemplates.golangstar()

# é€šç”¨åšå®¢é…ç½®
config = ConfigTemplates.generic_blog()

# æ˜é‡‘é…ç½®
config = ConfigTemplates.juejin()
```

### æ”¯æŒçš„ç½‘ç«™

| ç½‘ç«™ | é…ç½®æ–¹æ³• | åŸŸå |
|------|---------|------|
| é˜¿é‡Œäº‘å¼€å‘è€…ç¤¾åŒº | `ConfigTemplates.aliyun_developer()` | developer.aliyun.com |
| golangstar.cn | `ConfigTemplates.golangstar()` | golangstar.cn |
| æ˜é‡‘ | `ConfigTemplates.juejin()` | juejin.cn |
| é€šç”¨åšå®¢ | `ConfigTemplates.generic_blog()` | é€‚ç”¨äºå¤§å¤šæ•°åšå®¢ |

### æ·»åŠ è‡ªå®šä¹‰æ¨¡æ¿

åœ¨ `config.py` çš„ `ConfigTemplates` ç±»ä¸­æ·»åŠ ï¼š

```python
@staticmethod
def my_blog():
    """æˆ‘çš„åšå®¢é…ç½®"""
    return ExtractionConfig(
        base_url="https://myblog.com",
        main_content_selector="article",
        # ... å…¶ä»–é…ç½®
    )
```

## ğŸ“‹ å®Œæ•´ç¤ºä¾‹

```python
from WebContentExtractor import WebContentExtractor, ExtractionConfig

# 1. åˆ›å»ºé…ç½®
config = ExtractionConfig(
    base_url="https://golangstar.cn",
    output_dir="åç«¯é¢è¯•åœºæ™¯é¢˜",
    main_content_selector="main",
    skip_selectors=['nav', 'aside', 'footer'],
    download_images=True,
    delay=1.0,
    verbose=True
)

# 2. å‡†å¤‡æ–‡ç« åˆ—è¡¨
articles = [
    {
        "title": "å¦‚ä½•è®¾è®¡ä¸€ä¸ªåäº¿çº§çš„URLçŸ­é“¾ç³»ç»Ÿ",
        "url": "https://golangstar.cn/backend_series/advanced_interview/tinyurl.html"
    },
    {
        "title": "å¦‚ä½•è®¾è®¡ä¸€ä¸ªç™¾ä¸‡QPSçš„é™æµå™¨",
        "url": "https://golangstar.cn/backend_series/advanced_interview/rate_limiter.html"
    },
    # ... æ›´å¤šæ–‡ç« 
]

# 3. æ‰§è¡Œæå–
extractor = WebContentExtractor(config)
results = extractor.extract_articles(articles)

# 4. æŸ¥çœ‹ç»“æœ
print(f"æå–å®Œæˆ!")
print(f"æˆåŠŸ: {results['success_count']} ç¯‡")
print(f"å¤±è´¥: {results['fail_count']} ç¯‡")

if results['failed_urls']:
    print(f"å¤±è´¥çš„æ–‡ç« :")
    for item in results['failed_urls']:
        print(f"  - {item['title']}: {item['url']}")
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **éµå®ˆrobots.txt** - è¯·éµå®ˆç½‘ç«™çš„çˆ¬è™«åè®®
2. **æ§åˆ¶é¢‘ç‡** - è®¾ç½®åˆç†çš„ `delay` é¿å…å¯¹æœåŠ¡å™¨é€ æˆå‹åŠ›
3. **é€‰æ‹©å™¨å‡†ç¡®æ€§** - ä¸åŒç½‘ç«™çš„HTMLç»“æ„ä¸åŒï¼Œéœ€è¦è°ƒæ•´é€‰æ‹©å™¨
4. **ç½‘ç»œç¯å¢ƒ** - ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š
5. **æ³•å¾‹åˆè§„** - ä»…ç”¨äºä¸ªäººå­¦ä¹ ï¼Œä¸è¦ç”¨äºå•†ä¸šç”¨é€”
6. **æ¸…ç†ä¸´æ—¶è„šæœ¬** - æå–ä»»åŠ¡å®Œæˆåï¼Œå»ºè®®åˆ é™¤ä¸´æ—¶åˆ›å»ºçš„æå–è„šæœ¬ï¼ˆå¦‚ `extract_xxx.py`ï¼‰ï¼Œä¿æŒå·¥ä½œåŒºæ•´æ´

## ğŸ› æ•…éšœæ’é™¤

### é—®é¢˜1: æ‰¾ä¸åˆ°ä¸»å†…å®¹åŒºåŸŸ

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·æ£€æŸ¥ç½‘é¡µç»“æ„ï¼Œè°ƒæ•´ `main_content_selector`

```python
# å°è¯•ä¸åŒçš„é€‰æ‹©å™¨
config.main_content_selector = "article"  # æ ‡ç­¾å
config.main_content_selector = ".content"  # class
config.main_content_selector = "#main-content"  # id
config.main_content_selector = "div.post-body"  # ç»„åˆé€‰æ‹©å™¨
```

### é—®é¢˜2: æå–çš„å†…å®¹æ ¼å¼ä¸æ­£ç¡®

**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥ `skip_selectors`ï¼Œç¡®ä¿è·³è¿‡äº†ä¸éœ€è¦çš„å…ƒç´ 

```python
config.skip_selectors = ['nav', 'aside', 'footer', '.comments', '.sidebar']
```

### é—®é¢˜3: å›¾ç‰‡ä¸‹è½½å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**: æ£€æŸ¥ç½‘ç»œè¿æ¥ï¼Œæˆ–å…³é—­å›¾ç‰‡ä¸‹è½½

```python
config.download_images = False  # æš‚æ—¶å…³é—­å›¾ç‰‡ä¸‹è½½
config.timeout = 60  # å¢åŠ è¶…æ—¶æ—¶é—´
```

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.0.0 (2025-10-30)
- âœ¨ åˆå§‹ç‰ˆæœ¬å‘å¸ƒ
- âœ… æ”¯æŒæ‰¹é‡æ–‡ç« æå–
- âœ… æ”¯æŒå›¾ç‰‡è‡ªåŠ¨ä¸‹è½½
- âœ… æ”¯æŒå¤šç§æ ¼å¼ä¿ç•™
- âœ… å†…ç½®é¢„è®¾é…ç½®æ¨¡æ¿

## ğŸ“„ License

MIT License

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

## ğŸ’¡ ä½¿ç”¨æç¤º

1. **é¦–æ¬¡ä½¿ç”¨**: å»ºè®®å…ˆç”¨1-2ç¯‡æ–‡ç« æµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®
2. **è°ƒè¯•æ¨¡å¼**: è®¾ç½® `verbose=True` æŸ¥çœ‹è¯¦ç»†è¾“å‡º
3. **å¤‡ä»½æ•°æ®**: é‡è¦æ•°æ®è¯·åšå¥½å¤‡ä»½
4. **æ€§èƒ½ä¼˜åŒ–**: å¤§æ‰¹é‡æå–æ—¶å¯ä»¥å…³é—­å›¾ç‰‡ä¸‹è½½ï¼Œæé«˜é€Ÿåº¦
5. **ä»»åŠ¡å®Œæˆå**: åˆ é™¤ä¸´æ—¶æå–è„šæœ¬å’Œ `__pycache__` ç›®å½•ï¼Œä»…ä¿ç•™æå–çš„æ–‡ç« å†…å®¹

---

**äº«å—ä½¿ç”¨! å¦‚æœ‰é—®é¢˜è¯·æIssue.**
