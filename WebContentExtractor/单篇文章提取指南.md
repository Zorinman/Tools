# å•ç¯‡æ–‡ç« æå–æŒ‡å—

## ğŸ¯ å¿«é€Ÿå¼€å§‹ - æå–å•ç¯‡æ–‡ç« 

### æœ€ç®€å•çš„ç”¨æ³•ï¼ˆ3æ­¥å®Œæˆï¼‰

```python
from WebContentExtractor import WebContentExtractor, ConfigTemplates

# 1. é€‰æ‹©é¢„è®¾é…ç½®ï¼ˆæ ¹æ®ç½‘ç«™é€‰æ‹©ï¼‰
config = ConfigTemplates.aliyun_developer()  # é˜¿é‡Œäº‘å¼€å‘è€…ç¤¾åŒº
# config = ConfigTemplates.golangstar()      # golangstar.cn
# config = ConfigTemplates.juejin()          # æ˜é‡‘
# config = ConfigTemplates.generic_blog()    # é€šç”¨åšå®¢

# 2. è®¾ç½®è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º extracted_articlesï¼‰
config.output_dir = "æˆ‘çš„æ–‡ç« "

# 3. æå–æ–‡ç« ï¼ˆè‡ªåŠ¨æå–æ ‡é¢˜ï¼‰
extractor = WebContentExtractor(config)
results = extractor.extract_articles([
    {
        "title": "æ–‡ç« æ ‡é¢˜",  # ä¼šä½œä¸ºæ–‡ä»¶å¤¹åç§°
        "url": "https://developer.aliyun.com/article/1635071"
    }
])
```

### è¾“å‡ºç»“æ„

æå–åä¼šç”Ÿæˆä»¥ä¸‹ç»“æ„ï¼š

```
æˆ‘çš„æ–‡ç« /
â”œâ”€â”€ README.md                    # è‡ªåŠ¨ç”Ÿæˆçš„ç´¢å¼•
â””â”€â”€ æ–‡ç« æ ‡é¢˜/
    â”œâ”€â”€ æ–‡ç« æ ‡é¢˜.md              # æ–‡ç« å†…å®¹
    â””â”€â”€ imgs/                    # å›¾ç‰‡æ–‡ä»¶å¤¹
        â”œâ”€â”€ image_1.png
        â”œâ”€â”€ image_2.png
        â””â”€â”€ ...
```

## ğŸ“‹ æ”¯æŒçš„ç½‘ç«™é¢„è®¾é…ç½®

| ç½‘ç«™ | é…ç½®æ–¹æ³• | è¯´æ˜ |
|------|---------|------|
| é˜¿é‡Œäº‘å¼€å‘è€…ç¤¾åŒº | `ConfigTemplates.aliyun_developer()` | developer.aliyun.com |
| golangstar.cn | `ConfigTemplates.golangstar()` | golangstar.cn |
| æ˜é‡‘ | `ConfigTemplates.juejin()` | juejin.cn |
| é€šç”¨åšå®¢ | `ConfigTemplates.generic_blog()` | é€‚ç”¨äºå¤§å¤šæ•°åšå®¢ç½‘ç«™ |

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

å¦‚æœé¢„è®¾é…ç½®ä¸é€‚ç”¨ï¼Œå¯ä»¥è‡ªå®šä¹‰ï¼š

```python
from WebContentExtractor import WebContentExtractor, ExtractionConfig

config = ExtractionConfig(
    base_url="https://example.com",
    output_dir="æå–çš„æ–‡ç« ",
    main_content_selector=".article-content",  # æ–‡ç« ä¸»ä½“çš„CSSé€‰æ‹©å™¨
    title_selector="h1",                       # æ ‡é¢˜é€‰æ‹©å™¨
    skip_selectors=['nav', 'footer'],          # è¦è·³è¿‡çš„å…ƒç´ 
    download_images=True,                      # ä¸‹è½½å›¾ç‰‡
    images_folder_name="imgs",                 # å›¾ç‰‡æ–‡ä»¶å¤¹åç§°
)
```

### å¦‚ä½•æ‰¾åˆ°æ­£ç¡®çš„é€‰æ‹©å™¨ï¼Ÿ

1. **æ‰“å¼€æµè§ˆå™¨å¼€å‘è€…å·¥å…·**ï¼ˆF12ï¼‰
2. **ç‚¹å‡»å…ƒç´ é€‰æ‹©å™¨**ï¼ˆCtrl+Shift+Cï¼‰
3. **ç‚¹å‡»æ–‡ç« ä¸»ä½“åŒºåŸŸ**
4. **æŸ¥çœ‹HTMLç»“æ„**ï¼Œæ‰¾åˆ°åŒ…å«æ–‡ç« å†…å®¹çš„å…ƒç´ 
5. **å¸¸è§é€‰æ‹©å™¨**ï¼š
   - `article` - æ–‡ç« æ ‡ç­¾
   - `.article-content` - classé€‰æ‹©å™¨
   - `#main-content` - idé€‰æ‹©å™¨
   - `main` - mainæ ‡ç­¾

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q1: æå–çš„å†…å®¹ä¸å®Œæ•´ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼šè°ƒæ•´ `main_content_selector`

```python
# å°è¯•ä¸åŒçš„é€‰æ‹©å™¨
config.main_content_selector = "article"
config.main_content_selector = ".content"
config.main_content_selector = "#article-body"
```

### Q2: æå–äº†ä¸éœ€è¦çš„å†…å®¹ï¼ˆå¦‚å¯¼èˆªã€è¯„è®ºï¼‰ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼šæ·»åŠ åˆ° `skip_selectors`

```python
config.skip_selectors = ['nav', 'aside', 'footer', '.comments', '.sidebar']
```

### Q3: å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
# å¢åŠ è¶…æ—¶æ—¶é—´
config.timeout = 60

# æˆ–è€…æš‚æ—¶å…³é—­å›¾ç‰‡ä¸‹è½½
config.download_images = False
```

### Q4: æƒ³ä¿®æ”¹å›¾ç‰‡æ–‡ä»¶å¤¹åç§°ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š
```python
config.images_folder_name = "images"  # æˆ–å…¶ä»–åç§°
```

## ğŸ“ å®Œæ•´ç¤ºä¾‹

```python
from WebContentExtractor import WebContentExtractor, ConfigTemplates

# ä½¿ç”¨é˜¿é‡Œäº‘å¼€å‘è€…ç¤¾åŒºé…ç½®
config = ConfigTemplates.aliyun_developer()
config.output_dir = "æŠ€æœ¯æ–‡ç« "

# æå–å•ç¯‡æ–‡ç« 
extractor = WebContentExtractor(config)
results = extractor.extract_articles([
    {
        "title": "Kubernetesæ¶æ„è¯¦è§£",
        "url": "https://developer.aliyun.com/article/1635071"
    }
])

# æŸ¥çœ‹ç»“æœ
print(f"æˆåŠŸ: {results['success_count']} ç¯‡")
print(f"å¤±è´¥: {results['fail_count']} ç¯‡")
```

## âš™ï¸ é«˜çº§é…ç½®é€‰é¡¹

```python
config = ExtractionConfig(
    # åŸºæœ¬é…ç½®
    base_url="https://example.com",
    output_dir="extracted_articles",
    
    # é€‰æ‹©å™¨é…ç½®
    main_content_selector="article",
    title_selector="h1",
    skip_selectors=['nav', 'aside', 'footer'],
    
    # å›¾ç‰‡é…ç½®
    download_images=True,
    images_folder_name="imgs",
    image_skip_keywords=['icon', 'avatar', 'logo'],
    
    # æ ¼å¼é…ç½®
    preserve_bold=True,      # ä¿ç•™ç²—ä½“
    preserve_italic=True,    # ä¿ç•™æ–œä½“
    preserve_code=True,      # ä¿ç•™ä»£ç 
    preserve_links=True,     # ä¿ç•™é“¾æ¥
    
    # è¯·æ±‚é…ç½®
    timeout=30,              # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    delay=1.0,               # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
    
    # å…¶ä»–é…ç½®
    verbose=True,            # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    create_index=True,       # åˆ›å»ºç´¢å¼•æ–‡ä»¶
)
```

## ğŸš€ æ‰¹é‡æå–å¤šç¯‡æ–‡ç« 

```python
articles = [
    {"title": "æ–‡ç« 1", "url": "https://example.com/article1"},
    {"title": "æ–‡ç« 2", "url": "https://example.com/article2"},
    {"title": "æ–‡ç« 3", "url": "https://example.com/article3"},
]

extractor = WebContentExtractor(config)
results = extractor.extract_articles(articles)
```

---

**æç¤º**: é¦–æ¬¡ä½¿ç”¨å»ºè®®å…ˆæµ‹è¯•1ç¯‡æ–‡ç« ï¼Œç¡®è®¤é…ç½®æ­£ç¡®åå†æ‰¹é‡æå–ã€‚
